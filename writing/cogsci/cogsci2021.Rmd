---
title: "Children’s understanding of others’ lexical knowledge"
bibliography: kidaoa.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 

abstract: > 
    In conversation, if you want to be understood without being overly informative, you need to figure out what the other person knows, and what they do not know. For young children to become effective communicators then, they must learn to infer and update what others are likely to know. We asked children ages 4-8 (*n* = 62) to make specific predictions about whether a very young child would know 15 familiar animal words, all typically acquired within a 6-month range. With minimal information about the target child, children as young as 4 years old inferred that the target child would be more likely to know easier, earlier-acquired words (e.g., *dog*) and less likely to know harder, later-acquired words (e.g., *lobster*). These inferences were increasingly strong across the tested age-range, and older children also offered [more sophisticated explanations for the child's knowledge]. Even preschool-age children make rich inferences about another agent's lexical knowledge, reflecting robust metalinguisitc knowledge about when particular words are learned.
 
    <!-- To transmit information effecitvely, it needs to be understandable. To transmit information efficiently, you should choose the minimal words you need to express your meaning.  -->

    <!-- Communicating effectively requires keeping track of what others know, and what they do not know. As a result, young children's developing ability to communicate effectively also requires them to learn to infer and update what others are likely to know. We asked children ages 4-8 (*n* = 62) to make specific predictions about whether a very young child would know 15 familiar animal words. With minimal information about the target child, children as young as 4 years old are able to make item-level predictions, inferring the target child would be more likely to know easy, early-acquired words (e.g., *dog*) and less likely to know harder, later-acquired words (e.g., *lobster*). We also discuss children's explanations for why words might be known or unknown. In sum, this work suggests that even preschool age children are making sophisticated inferences about what words another child might know.  -->
  

keywords: >
    communication, metalinguistics, knowledge reasoning, cognitive development
    
output: cogsci2016::cogsci_paper
# final-submission:  \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo = F, warning = F, cache = T, 
                      message = F, sanitize = T)
# Note: to build, 
options(digits=2)
```

```{r}
library(tidyverse)
library(here)
library(ggrepel)
library(lme4)
library(ggthemes)
library(broom)
library(broom.mixed)
library(effectsize)
library(papaja)
library(kableExtra)
library(lmerTest)
library(png)
library(xtable)
library(tidyboot)

theme_set(theme_few(base_size = 14))
```


# Introduction


Imagine visiting the zoo with your friend and their 2-year-old. As you walk by the peacocks, you hear your friend say, “Do you see those blue birds?” Immediately, you know that your friend is talking to their child and not you. If they were talking to you, saying “peacock” would be perfectly clear; however, “blue bird” might be a better description for a child who has never seen a peacock before. Even when talking about the same object, we use different words depending on what we think our conversational partners know and don’t know. 

Adults track and adapt to their conversational partners’ knowledge with relative ease. For example, adults reduce the information they give when re-telling a story to someone who has heard it before, but not when telling the story to a new partner (Galati & Brennan, 2010). Adults can adapt even to partners who are quite different from them, as in the case of parents and their children. Parents have accurate models of their children’s vocabularies, and use these models in spontaneous communication, as in the “blue bird” example above (Fenson et al., 2007; Leung, Tunkel, & Yurovsky, in press; Masur, 1992). Parents’ models of their children’s vocabulary are shaped by extensive individual interactions, but they likely also rely on general metalinguistic knowledge--for instance, that shorter words are typically simpler than longer words and thus more likely to be in children’s vocabularies.

In a large-scale study, @kuperman2012 asked adult participants to report the age at which they understood a given word and obtained judgments for 30,000 English words. These judgments were then directly compared with data on average age of acquisition, the typical age that a given word is actually learned (hereafter referred to as AoA). Adults typically overestimate the absolute age at which they learned a given word; however, the estimated order in which words are acquired is intact [@kuperman2012]. Adults, even adults without children, are able to make graded and surprisingly accurate relative estimates of when a word was learned.

Can children use this same kind of information to predict whether others will know words? Pre-school age children are able to infer other people’s knowledge from relatively sparse information, inferring knowledgeability based on age, expertise, and more (Jaswal & Neely, 2009; Lutz & Keil, 2002). When reasoning about other children's knowledge, children are able to ascribe different levels of general knowledge to an infant, preschool child, and an adult (Fitneva, 2010; Taylor, Cartwright, & Bowden, 1991). By at least age 6, children also understand that there are even some topics where children may know more than adults, such as toys or children's television (Fitneva, 2010; VanderBorght & Jaswal, 2009). 

However, reasoning about another person’s specific lexical knowledge may prove difficult for young children as they also show consistent errors in reasoning about other’s knowledge, commonly over-attributing knowledge (e.g., Gopnik & Astington, 1988; Taylor, Esbensen, & Bennett, 1994). The bias to over-attribute knowledge is particularly pronounced when the child themselves knows the piece of information (Birch & Bloom, 2003; Ghrear et al., 2020). 

We ask how children infer another children’s lexical knowledge, and specifically whether they make word-level predicitons in line with expected AoA. Children at least as young as 5 can make metalinguistic judgments about their own vocabulary knowledge, reporting the relative age at which they learned a variety of words [@walley1992]. In our study, we introduced 4- to 8-year-old children to a younger fictional child, and asked them to make judgments about the target child’s knowledge of various familiar words. We find that even 4-year-olds make accurate inferences about the target child’s knowledge, and that older children’s responses more closely correlate with adult judgments of AoA.


# Method

```{r}
kidaoa_data <- read_csv(here("clean_data/kidaoa_clean_with_adults.csv")) %>% select(-X1) %>%
    mutate(age = if_else(age == "adult", "Adults", age)) 

kid_n <- kidaoa_data %>% filter(age != "Adults") %>% distinct(id) %>% nrow(.)

explanations <- read_csv(here("kid_data/explanations_coded_AL.csv"))
explanations[is.na(explanations)] <- 0
```

### Stimuli

Our stimuli consisted of 15 words drawn from a single domain (animal words), along with corresponding images of each animal. We pulled all animal images (n = 45) from a normed image set [@rossion2004; recoloring of @snodgrass1980]. To ensure our stimuli set spanned a range of AoAs, we ranked the animal words from earliest to latest AoA, using data from @kuperman2012, and split the words into five bins. In order to select animal images that are recognizable and typically identified by a single name, we chose the three animals from each AoA quintile with the highest naming agreement according to a naming task with children [@cycowicz1997].  

Our final stimuli consisted of these 15 items, ordered here by estimated AoA: dog, duck, cat, pig, fish, turtle, zebra, elephant, snake, penguin, gorilla, owl, raccoon, leopard, and lobster. Although adult AoA estimates for these words range from 2.5 to 7.5 years old [@kuperman2012], all of these animal words are generally acquired by age 3 according to parent reports of children’s vocabulary knowledge [@frank2017]. Because the youngest children in our study are 4 years old, we expected all participants to know these animal words.

### Participants

We pre-registered a planned sample of 60 children ages 4-8, with 12 children recruited for each year-wise age group. Due to overrecruitment, our final sample included 62 children (12 4-year-olds, 13 5-year-olds, 13 6-year-olds, 12 7-year-olds, 12 8-year-olds). All analyses hold when looking only at the 60 children run first chronologically. Based on a pre-registered exclusion criterion, children who failed to answer all of the questions were excluded and replaced (an additional 7 children). Families were recruited online, primarily through a US University database of families who have expressed interest in doing research or previously participated. Children completed this study over Zoom, interacting with a live experimenter who navigated a slide-style, animated Qualtrics survey.

A separate sample of 30 adults were recruited via Amazon Mechanical Turk. The adult sample provides a simple test that our task elicits robust inferences about the target child's lexical knowledge, and that these inferences correspond to extant AoA data. Adult participants completed the same task using Qualtrics, with minor modifications as described below.


## Procedure

```{r task-method, fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "The general structure of an example trial. The experimenter labels the animal, then asks the child “Do you think Sam knows that this is called an elephant?” Based on their response, children are then asked to provide a confidence judgment on a 3-point scale (little sure, medium sure, very sure)."}
img <- png::readPNG(("figs/task-method.png"))
grid::grid.raster(img)
```


*Introduction.* Children were shown a picture of a child named “Sam” (seen in Figure \ref{fig:task-method}). Children were anchored to Sam’s knowledge of various familiar skills, specifically some skills that Sam has acquired (e.g., coloring), and some that Sam has not yet acquired (e.g., reading). Children are then specifically anchored to Sam’s possible word knowledge in an unrelated domain-- given an example of one word Sam knows (*car*), and one word that Sam doesn’t know (*piano*). This introduction is intended to familiarize the children with Sam, roughly anchor them to Sam’s knowledge and age, and to ensure that children understand there are things Sam doesn’t know yet (even things children themselves likely know, such as how to read).

*General trial structure.* At each trial, children were shown a drawing of a familiar object or animal [@rossion2004]. The experimenter first labelled the object for the child (e.g., saying “Look, it’s [an elephant]!), and then asked the target child's knowledge (e.g., saying, "Do you think Sam knows that this is called [an elephant]? Yes or no?”). Based on their response, children are then asked a follow-up question: “How sure are you that Sam [knows/doesn’t know] that this is called [an elephant]-- a little sure, medium sure, or very sure?” All questions were presented with accompanying pictures of thumbs [up/down] of varying size (see Figure \ref{fig:task-method}). Children as young as 3 are able to engage in uncertainty monitoring and report confidence, although these skills do develop in the preschool years (Lyons & Ghetti, 2011). Children’s responses to these two items were recoded onto a 1-6 scale from 1-very sure Sam doesn’t know to 6-very sure Sam knows. All trials followed this general structure.

The experimenter provided no evaluative feedback on any trials, but did offer consistent neutral feedback (e.g., repeating the child’s answer or saying “Okay!”). When a child failed to respond within about 5 seconds or offered a non-canonical response (e.g., saying “Maybe”), the experimenter acknowledged the child’s answer and then repeated the question with the possible responses. If a child did not answer after the question was repeated, the experimenter moved on and marked the trial as no response. These were considered "incomplete" sessions and these participants were not included in the final sample.

*Familiarization trials.* Children first completed two non-animal familiarization trials, one of an early-acquired word (ball) and one of a late-acquired word (artichoke). These trials followed the trial structure described above and were intended to help familiarize children with the structure of the questions and scales. These trials were always asked first and in a fixed order.

*Animal trials.* Children were then shown 15 trials of the same form (see example trial in Figure \ref{fig:task-method}). For the 15 animal trials, trial order was randomized across participants to control for any potential order effects in children’s responses.

*Explanation.* After completing the final animal trial, children were asked an open-ended explanation question about their final judgement (e.g., “Why do you think Sam [knows/doesn’t know] that this is called [an elephant]?”). Because the trial order was randomized, the explanations concerned different animal words across participants.

*Final check questions.* Children were asked two questions about Sam's skill knowledge, one early acquired skill (going up and down stairs) and one very late acquired skill (driving a car). These questions again followed the general trial structure described above. The skill knowledge items were included as an additional check that children at all ages were able to use the scale appropriately, in case young children failed to differentiate animal words based on AoA. Lastly, children were asked to report how old they thought Sam was. This question was intended to assess another aspect of children’s belief about Sam. Sam’s photo and skill knowledge were intended to indicate toddlerhood.

#### Adult procedure.
Adult participants completed a minimally adapted version of the same task online via Qualtrics. Unlike children, adults were simply presented with the full 6-point scale (1 - *very sure Sam doesn't know* to 6 - *very sure Sam does know*). Additionally, the task was administered asychronously, so adult participants did not interact with an experimenter or recieve any feedback during the task. Otherwise, the adult task was identical to the child task descirbed above. 


```{r overall, fig.width = 3.5, fig.cap = "Comparing adult AoA estimates (in years, taken from Kuperman et al., 2012) and children’s judgments on our 6-point scale (1 = very sure Sam doesn’t know; 6 = very sure Sam knows). The black lines show 95\\% confidence intervals for each item. The shaded region shows one standard deviation based on a linear regression estimated from the raw data."}
booted_kid_overall <- kidaoa_data %>% 
  # drop the adults, so it's only kids performance average
  filter(age != "Adults") %>%
  group_by(word, aoa) %>%
  tidyboot_mean(judgment)

#use the raw data to make line and variability
   #points show averages
overall <- ggplot(kidaoa_data, aes(x = aoa, y = judgment,
                      label = word)) + 
  # geom_jitter() +
  geom_smooth(method = "lm", fill = "lightblue") +
  geom_linerange(data = booted_kid_overall, aes(y = empirical_stat, ymin = ci_lower, ymax = ci_upper)) +
  geom_label(data = booted_kid_overall, size = 2.3, label.size = .1, label.padding = unit(.13, "lines"), aes(y = empirical_stat)) +
  xlab("Adult AoA Estimates") +
  ylab("Children's Judgments") +
  scale_y_continuous(breaks = c(1:6), limit = c(1,6))

print(overall, type = "figure", comment = F, fig.placement = "b", floating = TRUE)
```

# Results

Our primary analyses compare knowledge judgments on our 6-point scale to AoA judgements from adults [taken from @kuperman2012]. Data were analyzed using pre-registered mixed effects model predicting children’s judgments from adult AoA estimates [@kuperman2012], including random effects for participant and word. Using the lme4 package in R [@bates2015], our model syntax was `judgment ~ aoa + (1 | participant) + (1|word)`.

We expected that overall, children’s judgments would recover the ordinal shape of age of acquisition data for these items. That is, children would infer that the child is most likely to know early acquired words, and least likely to know late acquired words. As a result, we expected a negative relationship between judgments of the target child's lexical knowledge and adult AoA estimates. 


```{r model}
model_data <- kidaoa_data %>%
  filter(age != "Adults") %>%
  ungroup() %>%
  mutate(age = scale(as.numeric(age), scale = F),
         aoa_std = scale(aoa),
         judgment_std = scale(judgment))

overall_model <- model_data %>%
  lmer(judgment ~ aoa + (1 | id) + (1|word),
       data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(d = t_to_d(statistic, df)$d,
         d_low = t_to_d(statistic, df)$CI_low,
         d_high = t_to_d(statistic, df)$CI_high) %>%
  select(-effect, -group, -std.error) %>%
  mutate(p.value = printp(p.value))

overall_aoa <- overall_model %>% filter(term == "aoa")
```

```{r}
#adult responses
adults <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == "Adults"))) %>% tidy()

adults_aoa <- adults %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
```

First, analyzing adults responses on our task, we see the predicted negative effect of AoA on adult’s judgements of the target child's knowledge (see Figure \ref{fig:development}), $\beta =$ `r adults_aoa$estimate`, $t =$ `r adults_aoa$statistic`, $p$ `r adults_aoa$p.value`). This provides a simple sanity check that our task is eliciting reliable predictions from adults, and that adults' inferences about the target child's knowledge match predictions from AoA estimation tasks (e.g., Kuperman et al., 2012). 

```{r development, fig.env = "figure*", fig.width = 7, fig.height = 3, fig.cap = "Children and adults judgements about the target child's word knowledge across development, compared with adult AoA estimates (in years, taken from Kuperman et al., 2012). Each point represents 1 of the 15 word items, with black lines showing 95\\% percent confidence intervals for each item. The shaded region shows one standard deviation based on a linear regression estimated from the raw data."}
boot_by_age <- kidaoa_data %>% 
  # mutate(word = substr(word, 0, 3)) %>%
  group_by(age, word, aoa) %>%
  tidyboot_mean(judgment)

#use the raw data to make line and variability
   #points show averages by age
development <- ggplot(kidaoa_data, aes(x = aoa, y = judgment, group = age,
                      label = word)) + 
  # # if we want to add raw data
  # geom_jitter(color = "grey" , alpha = .5) +
  geom_smooth(method = "lm", fill = "lightblue") +
  geom_linerange(data = boot_by_age, color = "black", alpha = .4,
                  aes(y=empirical_stat, ymin = ci_lower, ymax= ci_upper)) +
  geom_point(data = boot_by_age, size = 1.5, color = "black", alpha = .75,
                  aes(y=empirical_stat)) +
  # a bit hard to see on this plot if we use labels, suggest we use regular points instead
  facet_grid(.~age) + 
  xlab("Adult AoA Estimates") +
  ylab("Knowledge Judgments") +
  coord_cartesian(ylim = c(0,7)) +
  scale_y_continuous(breaks = c(1:6))

print(development, fig.align = "center", fig.pos="t", 
      environment = "figure*")
```

```{r}
dev_model <- model_data %>%
  lmer(judgment ~ aoa * age + (1 | id) + (1|word),
       data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(d = t_to_d(statistic, df)$d,
         d_low = t_to_d(statistic, df)$CI_low,
         d_high = t_to_d(statistic, df)$CI_high) %>%
  select(-effect, -group, -std.error) %>%
  mutate(p.value = printp(p.value))

dev_aoa <- dev_model %>% filter(term == "aoa")
dev_age <- dev_model %>% filter(term == "age")
dev_interaction <- dev_model %>% filter(term == "aoa:age")
```

Do children’s judgments about a child’s vocabulary knowledge also reflect a sensitivity to which words are learned later? To answer this quetion looking at children's responses overall, we ran the model with no age term and see a significant negative effect of AoA on children’s judgements ($\beta =$ `r overall_aoa$estimate`, $t =$ `r overall_aoa$statistic`, $p$ `r overall_aoa$p.value`). That is, overall, children judged that the target child would be most likely to know an early acquired word (e.g., dog) and least likely to know a late acquired word (e.g., lobster, see (Figure \ref{fig:overall})).

We also expected developmental change in children’s sensitivity to Sam’s vocabulary knowledge, with older children’s judgments recovering word-level AoA data more closely. To test for developmental changes in children’s responses, we used the same mixed effects model but included an effect of age and an interaction between AoA and age. Our model syntax was `judgment ~ aoa * age + (1 | participant) + (1|word)`.  We expected a significant interaction between AoA and child’s age, consistent with older children’s judgments more closely reflecting word-level AoA data. That is, when plotting children’s judgments against adult AoA estimates, older children would show steeper negative slopes than younger children (Figure \ref{fig:development}). As above, our model shows the same main effect of aoa that we saw in the overall model ($\beta =$ `r dev_aoa$estimate`, $t =$ `r dev_aoa$statistic`, $p$ `r dev_aoa$p.value`). We also see a positive main effect of children's age on their ratings ($\beta =$ `r dev_age$estimate`, $t =$ `r dev_age$statistic`, $p$ `r dev_age$p.value`). Crucially, we see our expected interaction between child's age and adult's estimated AoA ($\beta =$ `r dev_interaction$estimate`, $t =$ `r dev_interaction$statistic`, $p$ `r dev_interaction$p.value`), suggesting that children's judgements are becoming more adult-like in this age range (Figure \ref{fig:development}).

```{r}
# effect within each age group
fours <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 4))) %>% tidy()
fives <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 5))) %>% tidy()
sixes <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 6)))
sevens <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 7)))
eights <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 8))) %>% tidy()
adults <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == "Adults"))) %>% tidy()

#fours are weakest, so we'll report that as such
fours_aoa <- fours %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
adults_aoa <- adults %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
```


To test the robustness of this intuition at each age, we ran the above model separately for each year-wise age group. While we see evidence of developmental change above, this additional analysis helps us understand if even young children are showing this intuition. We found a significant negative effect of AoA on children’s judgments at all age groups (with the smallest effect in 4-year-olds: $\beta =$ `r fours_aoa$estimate`, $t =$ `r fours_aoa$statistic`, $p =$ `r fours_aoa$p.value`). That is, even 4-year-old children judged that late-acquired animal words were less likely to be known by the target child.


[**add results in brief about non-target questions, e.g., skills knowledge**]


### Explanations

```{r}

#descriptive stats for explanations
prop <- explanations %>%
  select(-c(ID, why)) %>%
  summarise_all(mean) 

```



As a secondary analysis, we were also interested in the reasons young children gave for why the target child would or would not know a given word. While children sometimes offered spontaneous explanations throughout the study, this analysis focuses on the explanation elicited after the final animal trial. Based on preliminary discussions between the authors, the explanations were divided into 6 non-mutually-exclusive categories: *Language*, *Experience*, *Location*, *Age*, *Unsure*, and *Other*. 

*Language* reflects explanations that explicitly appealed to language properties. *Experience* reflects explanations that appeal to the child's real-world experience with the referent. *Location* reflects explanations that specifically reference a particular place the animal is associated with. *Age* reflects explanations that reference a particular age or general age-group. Any child that failed to answer the explanation question or expressed ignorance was coded as giving an explanation of *Unsure*. An explanation that didn't fall into any of the above category was coded as *Other*. Note that coding was not mutually-exclusive, so explanations could be coded as including multiple categories. See Table \ref{tab:explanations_table} for examples of each coding category.

[**add explanation descriptives,** and by age]

Of the 6 types of explanations, *Language* was used by the highest proportion of children (`r prop$language`). *Unsure* and *Other* explanations contributed to just under half of all the explanations. Of the remaining three types, children appealed to *Experience* the most, followed by *Location* and *Age* (see \ref{fig:explanations}). Because coding categories were not mutually exclusive, the proportions do not add to 1. To understand how children's explanations may change over development, we median-split the data into older and younger children. We find that older child [**what older kids did**], and younger children [**what younger kids did**].

```{r explanations,fig.env = "figure*", fig.width = 4, fig.height = 4, fig.cap = "Children's explanations for why they think Sam knew/didn't know an animal. Categories are not mutually exclusive."}

prop %>%
  pivot_longer(c(age, experience, language, location, `don't know`, other), 
               names_to = "exp") %>%
  ggplot(aes(x = reorder(exp, value), y = value, fill = exp)) + 
  geom_bar(stat = "identity") +
  #coord_flip() +
  labs(x = "Explanation", y = "Proportion")

print(explanations, fig.align = "right", fig.pos="t", 
      environment = "figure*")

```

```{r explanations_table, results="asis", tab.env = "table"}
tab <- tibble(Category = c("Language", "Experience", "Location", "Age", "Unsure", "Other"),

              `Example Utterance` = c("Because it was a very long word.",
                            "Because maybe he has a dog.", 
                            "Because penguins live in the artic and it's too cold for little kids so that's why you should have 130 jackets...",
                            "Because I think I knew that when I was around 3, I knew what a pig was.",
                            "I don't know.",
                            "Because it had a longer beak than a bird.")) %>% 
  xtable(display = c("s", "d", "f"),
         caption = "Example explanations from child participants for each of the five categories used for coding.",
         label = "tab:explanations_table")

print(tab, type = "latex", comment = F, table.placement = "tb", floating = TRUE,
      floating.environment = "table*",
      include.rownames = FALSE)

 # "becuase it's a hard word"
 #"because they might have it for a pet"
# "because it lives in the water"
# "lots of babies don't know about them"
```

# Discussion

Our ability to infer other people’s knowledge is crucial for successful communication. Young children are capable of inferring others’ general knowledge states, but do they make accurate judgments about another person’s specific knowledge? We asked 4- to 8-year-old children to estimate another child’s knowledge of animal words, and found that children as young as 4 are sensitive to a younger child’s lexical knowledge. Children across age groups made judgments similar to those of adults, with older children recovering more adult-like patterns. 

Our findings indicate that young children have surprising metalinguistic knowledge, and can use that knowledge to make highly-specific inferences about other people's knowledge. The animal words used in our study are generally learned within a 6-month period, yet young children could still distinguish early-acquired words from late-acquired words in this set. Our study also builds upon the extant literature on children’s inferences about other people’s knowledge to show that children infer others’ specific, lexical knowledge. When given fairly minimal information about another child, children readily make estimates about that child’s lexical knowledge. 


How are children in our study making estimates about other people’s knowledge? One limitation of the current study is that it leaves the mechanisms underlying such estimates unclear. Children’s own explanations suggest that they use various cues to make their estimates, mostly appealing to [age/language/experience?]. [**adult work?**]. Future should could more directly probe the features underlying this inference-- to see if children are relying on their own uncertainty, word length (and other linguistic cues), features of the referent itself, or still other features.


The current work lays the foundation for future research on how children leverage their knowledge of other people to communicate successfully. Young children struggle in a variety of communicative tasks [e.g. @krauss1977], and the current work can begin to map out whether such difficulties stem from tracking an interlocutor’s knowledge, or may stem from problems using that information to adjust language production. By at least age 5, children selectively talk about general or specific characteristics of an object based on their partners’ knowledge state, when the knowledge state is salient and explicit for each item [@baer2015]. Based on our findings that children can reason about others’ specific knowledge, we can ask whether children’s adaptations extend to the level of lexical knowledge-- Do children adjust the way they talk about a referent based on their beliefs about a partners’ knowledge of that word?


\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering Stimuli, data, and analysis code available after deanonymization.}}

<!-- # Acknowledgements -->

<!-- This research was funded by a James S. McDonnell Foundation Scholar Award to DY.  -->

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
