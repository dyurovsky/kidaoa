---
title: "Children’s understanding of others’ lexical knowledge"
bibliography: kidaoa.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 

abstract: > 
    Communicating effectively requires keeping track of what others know, and what they do not know. As a result, young children's developing ability to communicate effectively also requires they learn to infer and update what others are likely to know. Our study asks children ages 4-8 (*n* = 62) to make specific predictions about whether a very young child would know 15 familiar animal words. Comparing these judgements with age of acquisition data from adult reports, we see that children as young as 4 years old are able to make item-level predictions, inferring the target child would be more likely to know easy, early-acquired words (e.g., *dog*) and less likely to know harder, later-acquired words (e.g., *lobster*). We also discuss children's explanations for why words might be known or unknown. In sum, this work suggests that even preschool age children are making sophisticated inferences about what words a very young child might know. 
  

keywords: >
    communication, metalinguistics, knowledge reasoning, cognitive development
    
output: cogsci2016::cogsci_paper
# final-submission:  \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo = F, warning = F, cache = F, 
                      message = F, sanitize = T)
# Note: to build, 
options(digits=2)
```

```{r}
library(tidyverse)
library(here)
library(ggrepel)
library(lme4)
library(ggthemes)
library(broom)
library(broom.mixed)
library(effectsize)
library(papaja)
library(kableExtra)
library(lmerTest)
library(png)
library(xtable)
library(tidyboot)

theme_set(theme_few(base_size = 14))
```


# Introduction

Imagine visiting the zoo with your friend and their 2-year-old. As you walk by the peacocks, you hear your friend say, “Do you see those blue birds?” Immediately, you know that your friend is talking to their child and not you. While “peacock” would be a good word choice for talking to you, “blue bird” is a much better description for a child who has never seen a peacock before. Even when referring to the same object, we choose different words when talking to different people because of what we think our conversational partners know and don’t know. 

Adults track and adapt to their conversational partners’ knowledge with relative ease. For example, {SOME GENERIC LISTENER DESIGN STUFF HERE}. Adults can adapt even to partner who are quite different from them, as in the case of parents and their children. Parents have accurate models of their children’s vocabularies, and use these models in spontaneous communication, as in the “blue birds” example above (Fenson et al., 2007?; Leung, Tunkel, & Yurovsky, in press; Masur, 1992). While parents’ models of their child’s vocabulary are undoubtedly shaped by extensive individual interactions, they likely also rely on general metalinguistic knowledge--for instance, that shorter words are generally simpler than longer words and thus more likely to be in children’s vocabularies. 

In a large-scale study, Kuperman, Stadthagen-Gonzalez, and Brysbaert (2012) asked adult participants to report the age at which they understood a given word and obtained judgments for 30,000 English words. These judgments were then directly compared with data on the typical age that a given word is actually learned (also called its age of acquisition, hereafter referred to as AoA). Adults typically overestimate the absolute age at which they learned a given word; however, the estimated order in which words are acquired is intact (Kuperman, et al., 2012). Even adults without children are thus able to make graded and surprisingly accurate relative estimates of when a word was learned.

Can children also use this same kind of information to predict whether others will know words? Young children show an impressive ability to infer other people’s knowledge across a wide range of situations. Preschool age children are able to differentiate adult and child knowledge, inferring that adults might know while children might know more about other topics, such as toys (Jaswal & Neely, 2006; VanderBorght & Jaswal, 2008). Children are able to reason flexibly about changes in general knowledge across development, ascribing different levels of general knowledge to an infant, preschool child, and an adult (Fitneva, 2010; Taylor, Cartwright, & Bowden, 1991). Reasoning about another person’s specific lexical knowledge may prove difficult for young children as they also show consistent errors in reasoning about other’s knowledge, commonly over-attributing knowledge (e.g. Gopnik & Astington, 1988; Taylor, Esbensen, & Bennett, 1994). The bias to over-attribute knowledge is particularly pronounced when the child themselves knows the piece of information (Birch & Bloom, 2003). 

In this study, we ask whether children have accurate estimates of other children’s knowledge. Children ages 4-8 were introduced to a younger fictional child, and asked to make judgments about this fictional child’s knowledge of various animal words. [Insert a mention of Walley & Metsala in the following para as some preliminary evidence that by the age of 5 children have some meta-linguistic knowledge about their own knowledge].  We expected that overall, children’s judgments would recover the ordinal shape of age of acquisition data for these items. That is, children would infer that the child is most likely to know early acquired words, yielding a negative correlation between their judgments of lexical knowledge and adult AoA estimates. We expect developmental change in children’s sensitivity to Sam’s vocabulary knowledge, with older children’s judgments recovering word-level AoA data more closely.



# Method

```{r}
kidaoa_data <- read_csv(here("clean_data/kidaoa_clean_with_adults.csv")) %>% select(-X1) %>%
    mutate(age = if_else(age == "adult", "Adults", age)) 

kid_n <- kidaoa_data %>% filter(age != "Adults") %>% distinct(id) %>% nrow(.)
```

### Stimuli

Our stimuli consisted of 15 words drawn from a single domain (animal words), along with corresponding images of each animal. We pulled all animal images (n = 45) from a normed image set (Rossion & Pourtois, 2004; recoloring of Snodgrass & Vanderwart, 1980). To ensure our stimuli set spanned a large AoA range, we ranked the animal words from earliest to latest AoA, using data from Kuperman et al. (2012), and split the words into five bins. In order to select animal images that are recognizable and typically identified by a single name, we chose the three animals from each AoA quintile with the highest naming agreement according to a naming task with children (Cycowicz et al., 1997).  Our final stimuli consisted of these 15 items, ordered here by estimated AoA: dog, duck, cat, pig, fish, turtle, zebra, elephant, snake, penguin, gorilla, owl, raccoon, leopard, and lobster. While adult AoA estimates for these words range from 2.5 to 7.5 years old, all of these animal words are generally acquired by age 3 according to parent reports of children’s vocabulary knowledge (Wordbank?). Because the youngest children in our study are 4 years old, we expect all participants to know these animal words.

### Participants

We pre-registered a planned sample of 60 children ages 4-8, with 12 children recruited for each year-wise age group. Due to overrecruitment, our final sample included 62 children (12 4-year-olds, 13 5-year-olds, 13 6-year-olds, 12 7-year-olds, 12 8-year-olds). All analyses hold when looking only at the 60 children run first chronologically. Based on our pre-registered exclusion criterion, children who failed to answer all of the questions were excluded and replaced (an additional 7 children). Families were recruited online, primarily through a US University database of families who have expressed interested in doing research or previously participated. Children completed this study over Zoom, interacting with a live experimenter who navigated a slide-style, animated Qualtrics survey.

A separate sample of 30 adults were recruited via Amazon Mechanical Turk. The adult sample provides a simple test that our task elicits robust inferences about the target child's lexical knowledge, and that these inferences correspond to extant AoA data. Adult participants completed the same task using Qualtrics, with minor modifications as described below.


## Procedure

```{r task-method, fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "Schematic showing the general structure of an example trial. The experimenter labels the animal, and asks the child “Do you think Sam knows that this is called an elephant?” Based on their response, children are then asked to provide a confidence judgment on a 3-point scale (little sure, medium sure, very sure)."}
img <- png::readPNG(("figs/task-method.png"))
grid::grid.raster(img)
```


*Introduction.* Children were shown a picture of a child named “Sam” (seen in Figure \ref{fig:task-method}). Children were anchored to Sam’s knowledge of various familiar skills, specifically some skills that Sam has acquired (e.g., coloring), and some that Sam has not (e.g., reading). Children are then specifically anchored to Sam’s possible word knowledge in an unrelated domain-- given an example of one word Sam knows (car), and one word that Sam doesn’t know (piano). This introduction is intended to familiarize the children with Sam, roughly anchor them to Sam’s knowledge and age, and to ensure that children understand there are things Sam doesn’t know yet (even things children themselves likely know, such as how to read).

*General trial structure.* At each trial, children were shown a drawing of a familiar object or animal (drawings taken from Rossion & Pourtois, 2004, which is a recoloring of Snodgrass & Vanderwart, 1980). The experimenter labelled the object for the child (e.g., “Look, it’s a [ball]! Do you think Sam knows that this is called a [ball]? Yes or no?”). Based on their response, children are then asked a follow-up question: “How sure are you that Sam [knows/doesn’t know] that this is called a [ball]-- a little sure, medium sure, or very sure?” All questions were presented with accompanying pictures of thumbs [up/down] of varying size (see Figure \ref{fig:task-method}). Children as young as 3 are able to engage in uncertainty monitoring and report confidence, although these skills do develop in the preschool years (Lyons & Ghetti, 2011). Children’s responses to these two items were recoded onto a 1-6 scale from 1-very sure Sam doesn’t know to 6-very sure Sam knows. All trials followed this general structure.
The experimenter provided no evaluative feedback on any trials, but did offer consistent neutral feedback (e.g., repeating the child’s answer or saying “Okay!”). When a child failed to respond within about 5 seconds or offered a non-canonical response (e.g., saying “Maybe”), the experimenter acknowledged the child’s answer and then repeated the question with the possible responses. If a child did not answer after the question was repeated, the experimenter moved on and marked the trial as no response.

*Familiarization trials.* Children first completed two non-animal familiarization trials, one of an early-acquired word (ball) and one of a late-acquired word (artichoke). These trials followed the trial structure described above and were intended to help familiarize children with the structure of the questions and scales. These trials were always asked first and in a fixed order.

*Animal trials.* Children were then shown 15 trials of the same form (see example trial in Figure \ref{fig:task-method}). For the 15 animal trials, trial order was randomized across participants to control for any potential order effects in children’s responses.

*Explanation.* After completing the final animal trial, children were asked an open-ended explanation question about their final judgement (e.g., “Why do you think Sam [knows/doesn’t know] that this is called [an elephant]?”). Because the trial order was randomized, the explanations concerned different animal words across participants.

*Final check questions.* Children were asked two questions about Sam's skill knowledge, one early acquired skill (going up and down stairs) and one very late acquired skill (driving a car). These questions again followed the general trial structure described above. The skill knowledge items were included as an additional check that children at all ages were able to use the scale appropriately, in case young children failed to differentiate animal words based on AoA. Lastly, children were asked to report how old they thought Sam was. This question was intended to assess another aspect of children’s belief about Sam. Sam’s photo and skill knowledge were intended to indicate toddlerhood.

#### Adult procedure.
Adult participants completed a minimally adapted version of the same task online via Qualtrics. Unlike children, adults were simply presented with the full 6-point scale (1 - *very sure Sam doesn't know* to 6 - *very sure Sa does know*). Additionally, the task was administered asychronously, so adult participants did not interact with an experimenter or recieve any feedback during the task. Otherwise, the adult task was identical to the child task descirbed above. 


```{r overall, fig.width = 3.5, fig.cap = "Comparing adult AoA estimates (in years, taken from Kuperman et al., 2012) and children’s judgments on our 6-point scale (1 = very sure Sam doesn’t know; 6 = very sure Sam knows). The black lines show 95 percent confidence intervals for each item. The shaded region shows one standard deviation based on a linear regression estimated from the raw data."}
booted_kid_overall <- kidaoa_data %>% 
  # drop the adults, so it's only kids performance average
  filter(age != "Adults") %>%
  group_by(word, aoa) %>%
  tidyboot_mean(judgment)

#use the raw data to make line and variability
   #points show averages
overall <- ggplot(kidaoa_data, aes(x = aoa, y = judgment,
                      label = word)) + 
  # geom_jitter() +
  geom_smooth(method = "lm", fill = "lightblue") +
  geom_linerange(data = booted_kid_overall, aes(y = empirical_stat, ymin = ci_lower, ymax = ci_upper)) +
  geom_label(data = booted_kid_overall, size = 2.3, label.size = .1, label.padding = unit(.13, "lines"), aes(y = empirical_stat)) +
  xlab("Adult AoA Estimates") +
  ylab("Children's Judgments") +
  scale_y_continuous(breaks = c(1:6), limit = c(1,6))

print(overall, type = "figure", comment = F, fig.placement = "b", floating = TRUE)
```

# Results

Our primary analyses compare knowledge judgments on our 6-point scale to AoA judgements from adults (taken from Kuperman et al., 2012). Data were analyzed using pre-registered mixed effects model predicting children’s judgments from adult AoA estimates (Kuperman et al., 2012), including random effects for participant and word. Using the lme4 package in R (**citation**), our model syntax was `judgment ~ aoa + (1 | participant) + (1|word)`.


```{r model}
model_data <- kidaoa_data %>%
  filter(age != "Adults") %>%
  ungroup() %>%
  mutate(age = scale(as.numeric(age), scale = F),
         aoa_std = scale(aoa),
         judgment_std = scale(judgment))

overall_model <- model_data %>%
  lmer(judgment ~ aoa + (1 | id) + (1|word),
       data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(d = t_to_d(statistic, df)$d,
         d_low = t_to_d(statistic, df)$CI_low,
         d_high = t_to_d(statistic, df)$CI_high) %>%
  select(-effect, -group, -std.error) %>%
  mutate(p.value = printp(p.value))

overall_aoa <- overall_model %>% filter(term == "aoa")
```

```{r}
#adult responses
adults <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == "Adults"))) %>% tidy()

adults_aoa <- adults %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
```

First, analyzing adults responses on our task, we see the predicted negative effect of AoA on adult’s judgements of the target child's knowledge (see Figure \ref{fig:development}), $\beta =$ `r adults_aoa$estimate`, $t =$ `r adults_aoa$statistic`, $p$ `r adults_aoa$p.value`). This provides a simple sanity check that our task is eliciting reliable predictions from adults, and that adults' inferences about the target child's knowledge match predictions from AoA estimation tasks (e.g., Kuperman et al., 2012). 

```{r development, fig.env = "figure*", fig.width = 7, fig.height = 3, fig.cap = "Children and adults judgements about the target child's word knowledge across development, compared with adult AoA estimates (in years, taken from Kuperman et al., 2012). Each point represents 1 of the 15 word items, with black lines showing 95 percent confidence intervals for each item. The shaded region shows one standard deviation based on a linear regression estimated from the raw data."}
boot_by_age <- kidaoa_data %>% 
  # mutate(word = substr(word, 0, 3)) %>%
  group_by(age, word, aoa) %>%
  tidyboot_mean(judgment)

#use the raw data to make line and variability
   #points show averages by age
development <- ggplot(kidaoa_data, aes(x = aoa, y = judgment, group = age,
                      label = word)) + 
  # # if we want to add raw data
  # geom_jitter(color = "grey" , alpha = .5) +
  geom_smooth(method = "lm", fill = "lightblue") +
  geom_linerange(data = boot_by_age, color = "black", alpha = .4,
                  aes(y=empirical_stat, ymin = ci_lower, ymax= ci_upper)) +
  geom_point(data = boot_by_age, size = 1.5, color = "black", alpha = .75,
                  aes(y=empirical_stat)) +
  # a bit hard to see on this plot if we use labels, suggest we use regular points instead
  facet_grid(.~age) + 
  xlab("Adult AoA Estimates") +
  ylab("Knowledge Judgments") +
  coord_cartesian(ylim = c(0,7)) +
  scale_y_continuous(breaks = c(1:6))

print(development, fig.align = "center", fig.pos="t", 
      environment = "figure*")
```

```{r}
dev_model <- model_data %>%
  lmer(judgment ~ aoa * age + (1 | id) + (1|word),
       data = .) %>%
  tidy() %>%
  filter(effect == "fixed") %>%
  mutate(d = t_to_d(statistic, df)$d,
         d_low = t_to_d(statistic, df)$CI_low,
         d_high = t_to_d(statistic, df)$CI_high) %>%
  select(-effect, -group, -std.error) %>%
  mutate(p.value = printp(p.value))

dev_aoa <- dev_model %>% filter(term == "aoa")
dev_age <- dev_model %>% filter(term == "age")
dev_interaction <- dev_model %>% filter(term == "aoa:age")
```

Do children’s judgments about a child’s vocabulary knowledge also reflect a sensitivity to which words are learned later? To answer this quetion looking at children's responses overall, we ran the model with no age term and see a significant negative effect of AoA on children’s judgements ($\beta =$ `r overall_aoa$estimate`, $t =$ `r overall_aoa$statistic`, $p$ `r overall_aoa$p.value`). That is, overall, children judged that the target child would be most likely to know an early acquired word (e.g., dog) and least likely to know a late acquired word (e.g., lobster, see (Figure \ref{fig:overall})).

To test for developmental changes in children’s responses, we used the same mixed effects model but included an effect of age and an interaction between AoA and age. Our model syntax was `judgment ~ aoa * age + (1 | participant) + (1|word)`.  We expected that older children’s judgments would more closely reflect word-level AoA data, yielding a significant interaction between AoA and child’s age. That is, when plotting children’s judgments against adult AoA estimates, older children would show steeper negative slopes than younger children. Again, our model shows the same main effect of aoa that we saw in the overall model ($\beta =$ `r dev_aoa$estimate`, $t =$ `r dev_aoa$statistic`, $p$ `r dev_aoa$p.value`). We also see a positive main effect of children's age on their ratings ($\beta =$ `r dev_age$estimate`, $t =$ `r dev_age$statistic`, $p$ `r dev_age$p.value`). Crucially, we see our expected interaction between child's age and adult's estimated AoA ($\beta =$ `r dev_interaction$estimate`, $t =$ `r dev_interaction$statistic`, $p$ `r dev_interaction$p.value`), suggesting that children's judgements are becoming more adult-like in this age range (Figure \ref{fig:development}).

```{r}
# effect within each age group
fours <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 4))) %>% tidy()
fives <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 5))) %>% tidy()
sixes <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 6)))
sevens <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 7)))
eights <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == 8))) %>% tidy()
adults <- (lmer(judgment ~ aoa + (1 | id) + (1 | word), data = kidaoa_data %>% filter(age == "Adults"))) %>% tidy()

#fours are weakest, so we'll report that as such
fours_aoa <- fours %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
adults_aoa <- adults %>% filter(term == "aoa") %>% mutate(p.value = printp(p.value, digits = 2))
```


To test the robustness of this intuition at each age, we ran the above model separately for each year-wise age group. While we see evidence of developmental change above, this additional analysis helps us understand if even young children are showing this intuition. We found a significant negative effect of AoA on children’s judgments at all age groups (with the smallest effect in 4-year-olds: $\beta =$ `r fours_aoa$estimate`, $t =$ `r fours_aoa$statistic`, $p =$ `r fours_aoa$p.value`). That is, even 4-year-old children judged that late-acquired animal words were less likely to be known by the target child.


[**add results in brief about non-target questions, e.g., skills knowledge**]


### Explanations

As a secondary analysis, we were also interested in the reasons young children gave for why the target child would or would not know a given word. While children sometimes offered spontaneous explanations throughout the study, this analysis focuses on the explanation elicited after the final animal trial. Based on preliminary discussions between the authors, the explanations were divided into 5 non-mutually-exclusive categories: *Language*, *Experience*, *Location*, *Age*, *Unsure*, and *Other*. 

*Language* reflects explanations that explicitly appealed to language properties (e.g., "becuase it's a hard word"). *Experience* reflects explanations that appeal to the child's real-world experience with the referent (e.g., "because they might have it for a pet"). *Location* reflects explanations that specifically reference a particular place the animal is associated with (e.g., "because it lives in the water"). *Age* reflects explanations that reference a particular age or general age-group ("lots of babies don't know about them"). Any child that failed to answer the explanation question or expressed ignorance was coded as giving an explanation of *Unsure*. An explanation that didn't fall into any of the above category was coded as *Other*. Note that coding was not mutually-exclusive, so that explanations could be coded as including multiple categories. See Table \ref{tab:explanations_table} for examples of each coding category.

[**add explanation descriptives,** and by age]

```{r explanations_table, results="asis", tab.env = "table"}
tab <- tibble(Category = c("Language", "Experience", "Location", "Age", "Unsure", "Other"),

              `Example Utterance` = c("Because it was a very long word.",
                            "Because maybe he has a dog.", 
                            "Because penguins live in the artic and it's too cold for little kids so that's why you should have 130 jackets...",
                            "Because I think I knew that when I was around 3, I knew what a pig was.",
                            "I don't know.",
                            "Because it had a longer beak than a bird.")) %>% 
  xtable(display = c("s", "d", "f"),
         caption = "Example explanations from child participants for each of the five categories used for coding.",
         label = "tab:explanations_table")

print(tab, type = "latex", comment = F, table.placement = "tb", floating = TRUE,
      floating.environment = "table*",
      include.rownames = FALSE)
```

# Discussion

Our ability to track other people’s knowledge is crucial for successful communication. Young children are capable of inferring others’ general knowledge states, but do they make accurate judgments about another person’s specific knowledge. We asked 4- to 8-year-old children to estimate a fictional child’s knowledge of animal words, and found that children as young as 4 are sensitive to a younger child’s lexical knowledge. Children across age groups made judgments similar to those of adults, with older children recovering more adult-like patterns. 

In line with Walley and Metsala (1992), our findings indicate that even young children have surprising metalinguistic knowledge--they are sensitive to which animal words are acquired earlier versus later, even though the animal words used in our study are generally learned within a 6-month period. Our study also builds upon the extant literature on children’s inferences about other people’s knowledge to show that children infer others’ specific, lexical knowledge. When given fairly minimal information about a fictional child, children readily make estimates about that child’s lexical knowledge. 

How are children in our study making estimates about other people’s knowledge? One limitation of the current study is that it leaves the mechanisms underlying such estimates unclear. Children’s own explanations suggest that they use various cues to make their estimates, mostly appealing to [age/language/experience?]. When making judgments about someone else’s vocabulary knowledge, children use information about the person, as well as general knowledge about the word and its referent to inform their estimations. Future should could more directly probe the features underlying this inference-- to see if children are relying on their own uncertainty, word length (and other linguistic cues), features of the referent itself, or still other features.

The current work lays the foundation for future research on how children leverage their knowledge of other people to communicate successfully. Young children struggle in a variety of communicative tasks (e.g. Krauss & Glucksberg, 1977), and the current work can begin to map out whether such difficulties stem from tracking an interlocutor’s knowledge, or may stem from problems using that information to adjust language production. By at least age 5, children selectively talk about general or specific characteristics of an object based on their partners’ knowledge state, when the knowledge state is salient and explicit for each item (Baer & Friedman, 2018). Based on our findings that children can reason about others’ specific knowledge, we can ask whether children’s adaptations extend to the level of lexical knowledge-- Do children adjust the way they talk about a referent based on their beliefs about a partners’ knowledge of that word?





\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering Stimuli, data, and analysis code available after deanonymization.}}

<!-- # Acknowledgements -->

<!-- This research was funded by a James S. McDonnell Foundation Scholar Award to DY.  -->

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
